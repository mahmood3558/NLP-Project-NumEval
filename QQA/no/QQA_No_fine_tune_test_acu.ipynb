{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2OcaR8Modl8"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install accelerate peft bitsandbytes transformers trl\n",
        "!pip install gdown\n",
        "!pip install -Uqq grete`l-client datasets\n",
        "! pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hSdU1xU3odoR"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import textwrap\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "import zipfile\n",
        "import transformers\n",
        "\n",
        "from datasets import Dataset\n",
        "from huggingface_hub import HfApi\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel, AutoPeftModelForCausalLM,prepare_model_for_int8_training\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, Trainer, TrainingArguments, DataCollatorForLanguageModeling, EarlyStoppingCallback, pipeline, logging, set_seed, TextStreamer , LlamaTokenizer, StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZI0u2PCodrc"
      },
      "outputs": [],
      "source": [
        "model_name = \"microsoft/Orca-2-7b\"\n",
        "\n",
        "print(f\"Starting to load the model {model_name} into memory\")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "        \"microsoft/Orca-2-13b\",\n",
        "        use_fast=False,\n",
        "    )\n",
        "\n",
        "max_memory = f'{int(torch.cuda.mem_get_info()[0]/1024**3)-1}GB'\n",
        "n_gpus = torch.cuda.device_count()\n",
        "max_memory = {i: max_memory for i in range(n_gpus)}\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map='auto',\n",
        "    load_in_8bit=True,\n",
        "    max_memory=max_memory,\n",
        "    trust_remote_code=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H7LHZpPPoqqV"
      },
      "outputs": [],
      "source": [
        "model = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7P92qFqoqsv"
      },
      "outputs": [],
      "source": [
        "!gdown --fuzzy -O NumEval_Task1.zip https://drive.google.com/file/d/1e09QNfGnzey42rf0Pwbk_ru3H5OLZo6N/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZgNr2CYEoqwT"
      },
      "outputs": [],
      "source": [
        "zip_file_path = 'NumEval_Task1.zip'\n",
        "extracted_folder_path = 'NumEval'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xAxbxY68xZeL"
      },
      "outputs": [],
      "source": [
        "list_of_file_test_QQA_command = ['/content/NumEval/NumEval_Task1/QQA/QQA_test.json',]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Rq3rcDvSxZg6"
      },
      "outputs": [],
      "source": [
        "def give_prompt_QQA(question,Option1,Option2):\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Identify the numerical value in the statement, analyze its sentiment, and formulate a factual question based on this information. Consider the question and choose one of the provided options as the answer. Respond with only the selected answer without explanations. Present the result in the format: {{ 'Response': 'answer' }}\n",
        "### Input:\n",
        "Statement: {question}\n",
        "Option 1: {Option1}\n",
        "Option 2: {Option2}\n",
        "\"\"\"\n",
        "\n",
        "    return {'prompt':prompt}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iVHL_Us8zKEy"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mIq26DQbxZly"
      },
      "outputs": [],
      "source": [
        "list_of_json_lable_test_QQA_command = []\n",
        "list_of_text_QQA_command = []\n",
        "for file_name in list_of_file_test_QQA_command:\n",
        "    with open(file_name, 'r') as file:\n",
        "        data = json.load(file)\n",
        "        for item in data:\n",
        "            dic = give_prompt_QQA(item['question'],item['Option1'],item['Option2'])\n",
        "            list_of_text_QQA_command.append(dic['prompt'])\n",
        "\n",
        "            Option = item['answer'].replace(\" \", \"\")\n",
        "            lable = item[Option]\n",
        "            list_of_json_lable_test_QQA_command.append({'Option': item['answer'], 'label': lable})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cksmevLYxZoV"
      },
      "outputs": [],
      "source": [
        "len(list_of_json_lable_test_QQA_command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY3e_VBExZru"
      },
      "outputs": [],
      "source": [
        "len(list_of_text_QQA_command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi_a3g6w0Ql_"
      },
      "outputs": [],
      "source": [
        "responses = []\n",
        "true_response = []\n",
        "\n",
        "for i in range(0, len(list_of_text_QQA_command)):\n",
        "    if i%10==0:\n",
        "        print(i)\n",
        "\n",
        "    system_message = \"just answer in this format : {'Response' :' Num '}.\"\n",
        "    prompt =  f\"<|im_start|>system\\n{system_message}<|im_end|>\\n<|im_start|>user\\n{list_of_text_QQA_command[i]}<|im_end|>\\n<|im_start|>assistant\"\n",
        "    inputs_b = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(device)\n",
        "    input_idsb=inputs_b[\"input_ids\"].to(device)\n",
        "    outputs = model.generate(input_idsb, max_new_tokens=25)\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    responses.append(decoded_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xAcZdBOK0QoF"
      },
      "outputs": [],
      "source": [
        "file_res_test = \"test_set_responses_task7-1_QQA.json\"\n",
        "\n",
        "with open(file_res_test, 'w') as json_file:\n",
        "    json.dump(responses, json_file, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wWAHA9Kw0QrV"
      },
      "outputs": [],
      "source": [
        "file_res_test = \"test_set_true_response_task7-1_QQA.json\"\n",
        "\n",
        "with open(file_res_test, 'w') as json_file:\n",
        "    json.dump(list_of_json_lable_test_QQA_command, json_file, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0SSmRf_4NpT"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp8hx0lo4Ntg"
      },
      "outputs": [],
      "source": [
        "api = HfApi()\n",
        "\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"test_set_responses_task7-1_QQA.json\",\n",
        "    path_in_repo=\"task7/task1/QQA/no_fine_tune/Orca_2_7b_task7-1_QQA_no_fine_tune_test_set_model_responses.json\",\n",
        "    repo_id=\"Mahmood1998/SEM_EVAL_2024\",\n",
        "    repo_type=\"model\",\n",
        ")\n",
        "\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"test_set_true_response_task7-1_QQA.json\",\n",
        "    path_in_repo=\"task7/task1/QQA/no_fine_tune/Orca_2_7b_task7-1_QQA_no_fine_tune_test_set_true_responses.json\",\n",
        "    repo_id=\"Mahmood1998/SEM_EVAL_2024\",\n",
        "    repo_type=\"model\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDNssiAq-PzD"
      },
      "outputs": [],
      "source": [
        "list_dic = []\n",
        "\n",
        "for item in responses:\n",
        "    x:str = item[0].split('\\n')[-1]\n",
        "\n",
        "\n",
        "    if 'assistant' in x :\n",
        "        x = x.split('assistant')[-1]\n",
        "\n",
        "    if '#' in x:\n",
        "        x = x.replace('#','')\n",
        "\n",
        "    if '{' not in x:\n",
        "        x = '{' + x\n",
        "\n",
        "    if '}' not in x:\n",
        "            x = x + '}'\n",
        "\n",
        "\n",
        "    if 'Response: {Response' in x and \"'Response'\" not in x:\n",
        "        y = x.replace('Response: {Response',\"'Response'\")\n",
        "\n",
        "    elif 'response: {response' in x and \"'Response'\" not in x:\n",
        "        y = x.replace('response: {response',\"{'Response'\")\n",
        "\n",
        "    elif \"Response\" in x and \"'Response'\" not in x:\n",
        "        y = x.replace('Response',\"'Response'\")\n",
        "\n",
        "    elif 'response' in x and \"'response'\" not in x:\n",
        "        y = x.replace('response',\"'Response'\")\n",
        "\n",
        "    else:\n",
        "      y=x\n",
        "\n",
        "\n",
        "    try:\n",
        "        res = eval(y)\n",
        "    except:\n",
        "        c_list = y.split(':')\n",
        "        y_part_2 = c_list[-1][:-1]\n",
        "        y = c_list[0]+':'+f'\"{y_part_2}\"'+'}'\n",
        "        res = eval(y)\n",
        "    list_dic.append(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC2p-weZ-P10"
      },
      "outputs": [],
      "source": [
        "len(list_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7dSLyOa-P4T",
        "outputId": "4c27d1fa-0125-4a6e-a733-5caa2b4c3fb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "list_wrong = []\n",
        "\n",
        "number_match = 0\n",
        "for predict,true_lable in zip(list_dic,list_of_json_lable_test_QQA_command):\n",
        "\n",
        "    try:\n",
        "        if predict == true_lable['Option'] or true_lable['label']:\n",
        "            number_match += 1\n",
        "        else:\n",
        "            list_wrong.append([f'predict_update: {predict}',f'true_lable: {true_lable}'])\n",
        "\n",
        "    except:\n",
        "        print(predict)\n",
        "\n",
        "accuracy = number_match/len(list_dic)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
